{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Building a Design Dataset\n",
    "\n",
    "Author: Stefan Abi-Karam\n",
    "\n",
    "This notebook will walk you through the process of building a design dataset from different sources. This includes using dataset retrievers to download and preprocess different design sources into a design dataset, as well as using design flows to generate more EDA and other data alongside the design sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Code\n",
    "\n",
    "Below is some initial notebook setup code to load juypter notebook extensions and include common imports needed throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset Creation Tools\n",
    "\n",
    "Below is code to import the `DesignDataset` class uses for creating and managing a design dataset, as well as various dataset retrievers for downloading and preprocessing different design sources from external sources into a design dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digital_design_dataset.dataset.datasets import (\n",
    "    EPFLDatasetRetriever,\n",
    "    HW2VecDatasetRetriever,\n",
    "    ISCAS85DatasetRetriever,\n",
    "    ISCAS89DatasetRetriever,\n",
    "    KoiosDatasetRetriever,\n",
    "    LGSynth89DatasetRetriever,\n",
    "    LGSynth91DatasetRetriever,\n",
    "    OPDBDatasetRetriever,\n",
    "    OpencoresDatasetRetriever,\n",
    "    VTRDatasetRetriever,\n",
    ")\n",
    "from digital_design_dataset.design_dataset import (\n",
    "    DesignDataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Design Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the current working directory. This is needed since `__file__` is not defined in Jupyter notebooks so we need to manually set the current working directory as if we are in the root of the repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_script_dir = Path(\"demo_scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can define a GitHub token to use for having a higher rate limit when dataset retrievers are downloading data from GitHub. It loads this token fromm a `.env` file sibling to the notebook.\n",
    "\n",
    "This is optional and can be set to `None` if you do not have a GitHub token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = dotenv_values(current_script_dir / \".env\")\n",
    "gh_token = None\n",
    "if \"GITHUB_TOKEN\" in env_config:\n",
    "    gh_token = env_config[\"GITHUB_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally we create the dataset!**\n",
    "\n",
    "We need to specify the dataset directory where the dataset will be on disk. We can also optionally specify weather we wan't to completely overwrite the dataset if it already exists as well as an optional GitHub token as previously mentioned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db_dir = current_script_dir / \"test_dataset_v2\"\n",
    "d = DesignDataset(\n",
    "    test_db_dir,\n",
    "    overwrite=True,\n",
    "    gh_token=gh_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add designs to this dataset using dataset retrievers.\n",
    "\n",
    "To use any dataset retrieve:\n",
    "\n",
    "1. create a dataset retriever instance by passing in a `DesignDataset` instance when creating the retriever\n",
    "2. call the `retrieve` method on the retriever to download and preprocess the design source into the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISCAS 85 Dataset Retriever\n",
    "\n",
    "This dataset retriever sources the ISCAS 85 benchmark.\n",
    "\n",
    "We source the benchmarks from here: [https://ddd.fit.cvut.cz/www/prj/Benchmarks/](https://ddd.fit.cvut.cz/www/prj/Benchmarks/). More work is being done to curate and mirror the original benchmarks ourselves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscas85_retriever = ISCAS85DatasetRetriever(d)\n",
    "iscas85_retriever.get_dataset()\n",
    "# iscas85_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISCAS 89 Dataset Retriever\n",
    "\n",
    "This dataset retriever sources the ISCAS 89 benchmark.\n",
    "\n",
    "We source the benchmarks from here: [https://ddd.fit.cvut.cz/www/prj/Benchmarks/](https://ddd.fit.cvut.cz/www/prj/Benchmarks/). More work is being done to curate and mirror the original benchmarks ourselves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iscas89_retriever = ISCAS89DatasetRetriever(d)\n",
    "iscas89_retriever.get_dataset()\n",
    "# iscas89_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGSynth 89 Dataset Retriever\n",
    "\n",
    "This dataset retriever sources the LGSynth 89 benchmark.\n",
    "\n",
    "We source the benchmarks from here: [https://ddd.fit.cvut.cz/www/prj/Benchmarks/](https://ddd.fit.cvut.cz/www/prj/Benchmarks/). More work is being done to curate and mirror the original benchmarks ourselves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgsynth89_retriever = LGSynth89DatasetRetriever(d)\n",
    "lgsynth89_retriever.get_dataset()\n",
    "# lgsynth89_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGSynth 91 Dataset Retriever\n",
    "\n",
    "This dataset retriever sources the LGSynth 91 benchmark.\n",
    "\n",
    "We source the benchmarks from here: [https://ddd.fit.cvut.cz/www/prj/Benchmarks/](https://ddd.fit.cvut.cz/www/prj/Benchmarks/). More work is being done to curate and mirror the original benchmarks ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgsynth91_retriever = LGSynth91DatasetRetriever(d)\n",
    "lgsynth91_retriever.get_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCores Dataset Retriever\n",
    "\n",
    "This dataset retriever sources hardware designs / IPs that we have currated from the [OpenCores](https://opencores.org/) website and [FreeCores](http://freecores.github.io/) mirror.\n",
    "\n",
    "We have packaged our curated designs here: [https://github.com/stefanpie/hardware-design-dataset-opencores](https://github.com/stefanpie/hardware-design-dataset-opencores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencores_retriever = OpencoresDatasetRetriever(d)\n",
    "opencores_retriever.get_dataset()\n",
    "# opencores_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW2VEC Dataset Retriever\n",
    "\n",
    "This dataset retriever sources the HW2VEC dataset. This dataset is a collection of designs from the HW2VEC paper. Many designs in HW2VEC are from other sources but are modified or tweaked for HW trojan detection and IP piracy detection research.\n",
    "\n",
    "The deigsn are sourced from the HW2VEC repository: [https://github.com/AICPS/hw2vec](https://github.com/AICPS/hw2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hw2vec_retriever = HW2VecDatasetRetriever(d)\n",
    "hw2vec_retriever.get_dataset()\n",
    "# hw2vec_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VTR Dataset Retriever\n",
    "\n",
    "This dataset retriever sources benchmark designs used in the Verilog-to-Routing (VTR) project. These benchmark designs are used to assess algorithm performance and Quality of Results (QoR) of the VTR tools.\n",
    "\n",
    "These designs are sourced from the VTR repository: [https://github.com/verilog-to-routing/vtr-verilog-to-routing](https://github.com/verilog-to-routing/vtr-verilog-to-routing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtr_retriever = VTRDatasetRetriever(d)\n",
    "vtr_retriever.get_dataset()\n",
    "# vtr_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koios Dataset Retriver\n",
    "\n",
    "This dataset retriever sources benchmark designs from the Koios 2.0 deep learning benchmark suite. This benchmark consists of designs which are deep learning accelerators. This benchmark was originally targeted for FPGA architecture and CAD research and is integrated into the Verilog-to-Routing benchmark evaluations.\n",
    "\n",
    "These designs are hosted and sources from the VTR repository: [https://github.com/verilog-to-routing/vtr-verilog-to-routing](https://github.com/verilog-to-routing/vtr-verilog-to-routing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koios_retriever = KoiosDatasetRetriever(d)\n",
    "koios_retriever.get_dataset()\n",
    "# kiois_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPFL Dataset Retriever\n",
    "\n",
    "This dataset retriever sources benchmark designs from the \"EPFL Combinational Benchmark Suite\". This benchmark suite is a collection of combinational circuits used for benchmarking logic optimization and synthesis algorithms.\n",
    "\n",
    "These designs are hosted and sourced from the EPFL benchmark repository: [https://github.com/lsils/benchmarks](https://github.com/lsils/benchmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epfl_retriever = EPFLDatasetRetriever(d)\n",
    "epfl_retriever.get_dataset()\n",
    "# epfl_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPDB Dataset Retriever\n",
    "\n",
    "This dataset retriever sources benchmark designs from the \"OpenPiton Design Benchmark\" (OPDB). These designs in this benchmark are created from the components of the [OpenPiton project](http://parallel.princeton.edu/openpiton/) and are used for benchmarking EDA tools.\n",
    "\n",
    "These designs are hosted and sourced from the OpenPiton Design Benchmark repository: [https://github.com/PrincetonUniversity/OPDB](https://github.com/PrincetonUniversity/OPDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opdb_retriever = OPDBDatasetRetriever(d)\n",
    "opdb_retriever.get_dataset()\n",
    "# opdb_retriever.remove_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Flows for Generating More Design Data\n",
    "\n",
    "In addition to design sources being part of a dataset, the user can run different tool flows to generate more data that sits alongside the design sources in the dataset. The flows themselves are arbitrary and user-defined, but our work defines a common interface for running these flows and interfacing with the dataset. Flows can be implemented in Python only (e.g., text processing and embedding) or can call out to external tools such as EDA tools to generate more data (e.g., synthesis, place and route, etc.).\n",
    "\n",
    "As with dataset retrievers, we include several flows as part of our framework. All the flows are still a work in progress and are being actively developed. We hope to cover a wide range of use cases such as different EDA tool flows and data processing tasks.\n",
    "\n",
    "Note that in this framework, not all flows need to be able to process all designs in the dataset. The framework is designed to be flexible and allow for different flows to apply to different subsets of designs as needed. Ideally, we are working towards having all built-in designs be supported by all built-in flows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Info Flow\n",
    "\n",
    "This flow generates hardware module information for each design using Yosys. Yosys reads in the design sources and generates all instantiated modules in the design. This list is then serialized and stored as part of the design in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digital_design_dataset.flows.flows import ModuleInfoFlow\n",
    "\n",
    "yosys_bin = \"yosys\"\n",
    "module_info_flow = ModuleInfoFlow(d, yosys_bin)\n",
    "module_info_flow.build_flow(n_jobs=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verible AST Flow\n",
    "\n",
    "This flow generates the syntax tree for the design sources present in a design using Verible. Verible is a suite of SystemVerilog tools that can be used to parse and analyze SystemVerilog code. We feed all the design sources into `verible-verilog-syntax` tool, and the syntax tree generated is serialized and stored as part of the design in the dataset.\n",
    "\n",
    "Warning: the syntax trees generated can take up a lot of disk space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digital_design_dataset.flows.flows import VeribleASTFlow\n",
    "\n",
    "verible_verilog_syntax_bin = \"verible-verilog-syntax\"\n",
    "verible_ast_flow = VeribleASTFlow(\n",
    "    d, verible_verilog_syntax_bin=verible_verilog_syntax_bin\n",
    ")\n",
    "verible_ast_flow.build_flow(n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yosys AIG Flow\n",
    "\n",
    "This flow generates a synthesized AIG netlist for a design using Yosys. Yosys reads the design sources and runs a coarse-grained generic synthesis flow. Then, the AIG pass is called to convert the synthesized netlist into an AIG netlist. This AIG netlist is then serialized and stored as part of the design in the dataset.\n",
    "\n",
    "Warning: the netlist generated can take up a lot of disk space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from digital_design_dataset.flows.flows import YosysAIGFlow\n",
    "\n",
    "yosys_bin = \"yosys\"\n",
    "yosys_ast_flow = YosysAIGFlow(d, yosys_bin=yosys_bin)\n",
    "yosys_ast_flow.build_flow(n_jobs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
